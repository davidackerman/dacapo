## Tasks:

### How they work:
Tasks are split up into
1) predictors
2) losses
3) post_processors

Tasks also have data augmentations defined on them. These are here temporarily since
we do not yet have a batch_generator config. Data augmentations can improve your training
by mirroring/rotating/stretching/adding noise/randomising intensity and more.

#### Predictor
A `Predictor` is basically a "head" on the "backbone" defined in your `Model` config.
It takes in the features generated by your model and transforms them into a usable output.
For example generating affinities for instance segmentation. For more info read the
`Predictor` README at "dacapo/tasks/predictors/README.md"

#### Loss
Each `Predictor` needs to have its own `Loss`. Total loss is the product of each loss applied
to each `Predictor` output and the ground truth.

#### PostProcessor
A `PostProcessor` takes the output created by a predictor and transforms it into a more
usable format. For example taking affinities produced by an affinities `Predictor`, and
running watershed+agglomeration to generate whole segmentations. For more info read the
`PostProcessor` README at "dacapo/tasks/post_processors/README.md"